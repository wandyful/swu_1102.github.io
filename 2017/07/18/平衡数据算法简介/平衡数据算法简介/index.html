<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      不平衡数据处理简介 | 王宇峰的博客 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="王宇峰">
    
    

    <meta name="description" content="[toc] ##概述在数据挖掘中，经常会存在不平衡数据的分类问题，比如在提取环评信息中的总投资额，由于采样时反例的比例远远大于正例，因此想要达到良好的识别效果普通的分类算法还远远不够，这里介绍几种处理不平衡数据的常用方法及对比。迄今为止 , 解决不平衡分类问题的策略可以分为两大类 。一类是从训练集入手 , 通过改变训练集样本分布 ,降低不平衡程度 .另一类是从学习算法入手，根据算法在解决不平衡问题">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="不平衡数据处理简介 | 王宇峰的博客">
<meta property="og:url" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/index.html">
<meta property="og:site_name" content="王宇峰的博客">
<meta property="og:description" content="[toc] ##概述在数据挖掘中，经常会存在不平衡数据的分类问题，比如在提取环评信息中的总投资额，由于采样时反例的比例远远大于正例，因此想要达到良好的识别效果普通的分类算法还远远不够，这里介绍几种处理不平衡数据的常用方法及对比。迄今为止 , 解决不平衡分类问题的策略可以分为两大类 。一类是从训练集入手 , 通过改变训练集样本分布 ,降低不平衡程度 .另一类是从学习算法入手，根据算法在解决不平衡问题">
<meta property="og:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250121547.png">
<meta property="og:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250656091.png">
<meta property="og:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250685260.png">
<meta property="og:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250713776.png">
<meta property="og:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250734299.png">
<meta property="og:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250882309.png">
<meta property="og:updated_time" content="2017-08-09T05:47:30.273Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="不平衡数据处理简介 | 王宇峰的博客">
<meta name="twitter:description" content="[toc] ##概述在数据挖掘中，经常会存在不平衡数据的分类问题，比如在提取环评信息中的总投资额，由于采样时反例的比例远远大于正例，因此想要达到良好的识别效果普通的分类算法还远远不够，这里介绍几种处理不平衡数据的常用方法及对比。迄今为止 , 解决不平衡分类问题的策略可以分为两大类 。一类是从训练集入手 , 通过改变训练集样本分布 ,降低不平衡程度 .另一类是从学习算法入手，根据算法在解决不平衡问题">
<meta name="twitter:image" content="http://yoursite.com/2017/07/18/平衡数据算法简介/平衡数据算法简介/1502250121547.png">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">王宇峰的博客</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">不平衡数据处理简介</h1>

    

    <div class="post-meta">
      <time datetime="2017-07-18" class="post-meta__date date">2017-07-18</time> 

      <span class="post-meta__tags tags">

          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/机器学习/">机器学习</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <p>[toc]</p>
<p>##概述<br>在数据挖掘中，经常会存在不平衡数据的分类问题，比如在提取环评信息中的总投资额，由于采样时反例的比例远远大于正例，因此想要达到良好的识别效果普通的分类算法还远远不够，这里介绍几种处理不平衡数据的常用方法及对比。迄今为止 , 解决不平衡分类问题的策略可以分为两大类 。一类是从训练集入手 , 通过改变训练集样本分布 ,降低不平衡程度 .另一类是从学习算法入手，根据算法在解决不平衡问题时的缺陷，适当地修改算法使之适应不平衡分类问题 。</p>
<p>##数据层面</p>
<p>###过采样方法</p>
<p>####Synthetic Minority Oversampling Technique(SMOTE)<br>方法步骤：</p>
<ol>
<li>计算点p在少类样本中的k个最近邻</li>
<li>有放回地随机抽取R≤k个邻居</li>
<li>对这R个点，每一个点与点p可以组成一条直线，然后在这条直线上随机取一个点，就产生了一个新的样本，一共可以这样做从而产生R个新的点。</li>
<li>将这些新的点加入少类样本中<br><img src="./1502250121547.png" alt="Alt text"><h4 id="Borderline-SMOTE1"><a href="#Borderline-SMOTE1" class="headerlink" title="Borderline-SMOTE1"></a>Borderline-SMOTE1</h4>对于少数类中的某一点P<ol>
<li>计算点p在训练集T上的m个最近邻。我们称这个集合为Mp然后设 m’= |Mp ∩ L| (表示点p的最近邻中属于L的数量).</li>
<li>If m’= m, p 是一个噪声,不做任何操作.</li>
<li>If 0 ≤m’≤m/2, 则说明p很安全，不做任何操作.</li>
<li>If m/2 ≤ m’≤ m, 那么点p就很危险了，我们需要在这个点附近生成一些新的少数类点，所以我们把它加入到DANGER中.<br>最后，对于每个在DANGER中的点d，使用SMOTE算法生成新的样本.<br>####Borderline-SMOTE2<br>类似Borderline-SMOTE1，但在DANGER集中的点不仅从S集中求最近邻并生成新的少数类点，而且在L集中求最近邻，并生成新的少数类点，这会使得少数类的点更加接近其真实值。<br>对于在danger中的某一点P<br>1.在S和L中分别得到k个最近邻样本Sk和Lk。<br>2.在Sk中选出α比例的样本点和p作随机的线性插值产生新的少数类样本<br>3.在Lk中选出1−α比例的样本点和p作随机的线性插值产生新的少数类样本。1<br>###欠采样方法<br>####Edited Nearest Neighbor (ENN)<br>原理简介：我们将那些多数类的样本，如果他的大部分k近邻样本都跟他自己本身的类别不一样，我们就将他删除。<br>####Repeated Edited Nearest Neighbor<br>这个方法就是不断的重复上述的删除过程，直到无法再删除为止。<br>####Tomek Link Removal<br>如果有两个不同类别的样本，它们的最近邻都是对方，也就是A的最近邻是B，B的最近邻是A，那么A,B就是Tomek link。我们要做的就是讲所有Tomek link都删除掉。那么一个删除Tomek link的方法就是，将组成Tomek link的两个样本，如果有一个属于多数类样本，就将该多数类样本删除掉。<br>####组合方法<br>(1) SMOTE + Tomek Link Removal<br>(2) SMOTE + ENN<br>##算法层面<br>###EasyEnsemble<br>多次放回采样（这样产生的训练集才相互独立）产生多个不同的训练集，进而训练多个不同的分类器，通过组合多个分类器的结果得到最终的结果。<br>实际上easy ensemble每次从多数类中抽样出和少数类数目差不多的样本，然后和少数类样本组合作为训练集。在这个训练集上学习一个adaboost分类器。 最后预测的时候，是使用之前学习到的所有adaboost中的弱分类器（就是每颗决策树）的预测结果向量（每个树给的结果组成一个向量）和对应的权重向量做内积，然后减去阈值，根据差的符号确定样本的类别。（并非根据每个adaboost的预测结果做多数表决）<br>伪代码如下：<br><img src="./1502250656091.png" alt="Alt text"><br>###BalanceCascad<br>这个方法跟EasyEnsemble有点像，但不同的是，每次训练adaboost后都会扔掉已被正确分类的样本，经过不断地扔掉样本后，数据就会逐渐平衡伪代码如下:<br><img src="./1502250685260.png" alt="Alt text"><br>可以看出balance cascade算法和easy ensemble还是挺像的，差别就在第7步和第8步。<br>第6步，算法训练出一个分类器，然后在第7步调整分类器H i的阈值θi以保证分类器H i   的false positive rate w为f。而f的定义为:<br><img src="./1502250713776.png" alt="Alt text"><br>这样的话，根据H i 的阈值θi对所有的多数类样本进行预测，如果样本的估计值大于该阈值则判定为正例（即少数类），这些都是预测错误的多数类样本。如果样本的估计值小于阈值则判定为负例（即多数类），这些就是预测正确的多数类样本，第8步中去掉的也就是这一部分样本，而这些样本占当前所有多数类的样本是1−f ,即每次迭代多数类样本保留下来的比例为f ,那么T-1次后，多数类样本还剩 <img src="./1502250734299.png" alt="Alt text"><br>个，那么在第T次迭代中，多数类样本就会少于少数类样本，此时可以停止迭代。<br>###特征选择方法<br>特征选择方法对于不平衡分类问题同样具有重要意义 .样本数量分布很不平衡时,特征的分布同样会不平衡.尤其在文本分类问题中,在大类中经常出现的特征,也许在稀有类中根本不出现 .因此 ,根据不平衡分类问题的特点 , 选取最具有区分能力的特征 ,有利于提高稀有类的识别率 。<br>####第一类：Filter方法. <blockquote>
<p>其主要思想是：对每一维的特征“打分”，即给每一维的特征赋予权重，这样的权重就代表着该维特征的重要性，然后依据权重排序。</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<p>####卡方检验<br>最基本的思想就是通过观察实际值与理论值的偏差来确定理论的正确与否。具体做的时候常常先假设两个变量确实是独立的（“原假设”），然后观察实际值（观察值）与理论值（这个理论值是指“如果两者确实独立”的情况下应该有的值）的偏差程度，如果偏差足够小，我们就认为误差是很自然的样本误差，是测量手段不够精确导致或者偶然发生的，两者确确实实是独立的，此时就接受原假设；如果偏差大到一定程度，使得这样的误差不太可能是偶然产生或者测量不精确所致，我们就认为两者实际上是相关的，即否定原假设，而接受备择假设。<br>理论值为E，实际值为x，偏差程度的计算公式为：<br><img src="./1502250882309.png" alt="Alt text"><br>这个式子就是开方检验使用的差值衡量公式。当提供了数个样本的观察值x1，x2，……xi，……xn之后，代入到式中就可以求得开方值，用这个值与事先设定的阈值比较，如果大于阈值（即偏差很大），就认为原假设不成立，反之则认为原假设成立。<br>在文本分类的特征选择阶段，一般使用“词t与类别c不相关”来做原假设，计算出的开方值越大，说明对原假设的偏离越大，我们越倾向于认为原假设的反面情况是正确的。选择的过程为每个词计算它与类别c的开方值，从大到小排个序（此时开方值越大越相关），取前k个就可以。</p>
<p>#####信息增益（IG，Information Gain）<br>信息熵是一个变量可能的变化越多（反而跟变量具体的取值没有任何关系，只和值的种类多少以及发生概率有关），它携带的信息量就越大。<br>一个系一个特征t，系统有它和没它的时候信息量各是多少，两者的差值就是这个特征给系统带来的信息量统越是有序，信息熵就越低；反之，一个系统越乱，信息熵就越高。所以，信息熵也可以说是系统有序化程度的一个衡量。<br>是指期望信息或者信息熵的有效减少量。<br>对于一个特征t，系统有它和没它的时候信息量各是多少，两者的差值就是这个特征给系统带来的信息量。有它即信息熵，无它则是条件熵。<br>条件熵：计算当一个特征t不能变化时，系统的信息量是多少。<br>对于一个特征X，它可能的取值有n多种（x1，x2，……，xn），计算每个值的条件熵，再取平均值。<br>但信息增益最大的问题还在于它只能考察特征对整个系统的贡献，而不能具体到某个类别上，这就使得它只适合用来做所谓“全局”的特征选择（指所有的类都使用相同的特征集合），而无法做“本地”的特征选择（每个类别有自己的特征集合，因为有的词，对这个类别很有区分度，对另一个类别则无足轻重）。</p>
<p>####第二类：Wrapper方法。</p>
<blockquote>
<p>其主要思想是：将子集的选择看作是一个搜索寻优问题，生成不同的组合，对组合进行评价，再与其他的组合进行比较。</p>
</blockquote>
<p>主要方法有：recursive feature elimination algorithm(递归特征消除算法)</p>
<p>####第三类：Embedded方法</p>
<blockquote>
<p>其主要思想是：在模型既定的情况下学习出对提高模型准确性最好的属性。这句话并不是很好理解，其实是讲在确定模型的过程中，挑选出那些对模型的训练有重要意义的属性。</p>
<p>主要方法：正则化，可以见“简单易学的机器学习算法——岭回归(Ridge Regression)”，岭回归就是在基本线性回归的过程中加入了正则项。</p>
<p>##关于处理数据不平衡方法选择建议<br>1、在正负样本都非常之少的情况下，应该采用类似过采样的方法。<br>2、在负样本足够多，正样本非常之少且比例及其悬殊的情况下，可以考虑欠采样的方法。<br>3、如果待分类的样本中，负样本中有一部分和正样本距离很近，但是另一部分却和正样本距离很远，可以考虑采用组合过采样和欠采样的方法。<br>3、在正负样本都足够多且比例不是特别悬殊的情况下，应该考虑特征选择的方法。<br>4、另外，虽然过采样和欠采样都可以使数据集变得平衡，并且在数据足够多的情况下等价，但两者也是有区别的。实际应用中，过采样会增加训练集的大小进而增加训练时间，同时小的训练集非常容易产生过拟合。<br>6、如果计算资源相对较多且有良好的并行环境，可以考虑选择Ensemble方法。</p>
</blockquote>
<p>整理自:<a href="http://blog.csdn.net/a358463121" target="_blank" rel="external">http://blog.csdn.net/a358463121</a><br><a href="http://blog.csdn.net/Yaphat/article/details/52463304?locationNum=7" target="_blank" rel="external">http://blog.csdn.net/Yaphat/article/details/52463304?locationNum=7</a></p>


  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    <!-- UY BEGIN -->
	<div id="uyan_frame"></div>
	<script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2140946"></script>
	<!-- UY END -->

</section>

</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
